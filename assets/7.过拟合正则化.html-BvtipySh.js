import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,o as t,d as i}from"./app-DQsaqGl9.js";const l={},n=i('<p>过拟合：模型学习能力太强，学到了样本数据不具备普遍性的特征</p><p>泛化性：模型应用到新样本的能力</p><p>一般解决方法：</p><ul><li>特征选择：丢弃一些不能帮助我们正确预测的特征。可以是手工选择保留哪些特征，或者使用一些模型选择的算法来帮忙（例如<strong>PCA</strong>）</li><li>正则化：保留所有特征，但是减少参数量，降低模型复杂度，从而防止过拟合</li><li>得到更多数据：增大数据量、数据增强</li></ul><h2 id="正则化" tabindex="-1"><a class="header-anchor" href="#正则化"><span>正则化</span></a></h2><p>原理：通过在损失函数中加入额外的约束或惩罚项，控制模型的复杂度，从而提高模型在新数据上的泛化能力</p><p>很多地方都说到正则化，但其实具体怎么用，用在哪里是不一样的：</p><ul><li>将正则化项加在代价函数上：目标函数 = 代价函数 + λ 正则化项，这里 λ是正则化系数</li><li>优化器上对参数的更新的时候减去一个正则化项，也叫<strong>权重衰减</strong></li></ul><p>本质上两者其实是等价的，都是可以减少参数量，降低模型复杂度，从而防止过拟合</p><h3 id="l1正则化" tabindex="-1"><a class="header-anchor" href="#l1正则化"><span>L1正则化</span></a></h3><p>定义：在损失函数中添加参数的 L1 范数（元素/参数绝对值之和）乘上正则化系数的正则化项：$$\\lambda \\sum_{j=1}^{n} |W_j|$$</p><p>求导：求导后为符号函数$$sign(W_i)$$</p><p>作用：使得<strong>参数稀疏[权重稀疏]</strong>，有<strong>特征选择</strong>的效果。保留重要特征，不重要特征权重为0</p><h4 id="具体分析" tabindex="-1"><a class="header-anchor" href="#具体分析"><span>具体分析</span></a></h4><p>因为求导后为符号函数$$sign(W_i)$$，每次更新都会向零靠近，多次迭代后某些参数会变为0</p><p>更正：不用除以样本数量</p><figure><img src="https://pq18uqc90b.feishu.cn/space/api/box/stream/download/asynccode/?code=MGI3NGFhNmUyOGE1ZmI2ZDhmZGJlY2I0NGVjZDk4N2JfbVNtYXU1SzM3dDhQZTZMOVlVZVVJU3pLakdwem8zN1VfVG9rZW46TUk0RmJ5TDdQb2J5bmR4N2hRcmNXWGlQbm9lXzE3NDI4OTk2NzA6MTc0MjkwMzI3MF9WNA" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h3 id="l2正则化" tabindex="-1"><a class="header-anchor" href="#l2正则化"><span>L2正则化</span></a></h3><p>定义：在损失函数中添加参数的 L2 范数（参数平方和开平方根）乘上正则化系数的的正则化项：$$\\lambda \\sum_{j=1}^{n} ||W_j||<em>2^2 = \\lambda \\sum</em>{j=1}^{n} (W_j)^2$$</p><p>L2范数：$$||W||_2 = \\sqrt{W^2}$$</p><p>求导：求导后为参数本身$$W_j$$，每次更新会减小[根据学习率]，接近0但不会变为严格的0</p><p>作用：<strong>缩小权重[权重平滑]</strong> 。选择更多的特征，缩小权重数值，使得参数估计更加稳定</p><h4 id="具体分析-1" tabindex="-1"><a class="header-anchor" href="#具体分析-1"><span>具体分析</span></a></h4><p>更正：不用除以样本数量</p><figure><img src="https://pq18uqc90b.feishu.cn/space/api/box/stream/download/asynccode/?code=ZGMzZmUxNDgxZjFkMGRjZjBhYWRkMWE1MWMxZDBkOTRfVkZXZjVlallkYXU5N2k0RGZKcEVJTGJGa1hxOEdYN25fVG9rZW46QnJvTGI2SlM3b0dPaDh4UE9lQ2NtVjUwbkZnXzE3NDI4OTk2NzA6MTc0MjkwMzI3MF9WNA" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h2 id="dropout" tabindex="-1"><a class="header-anchor" href="#dropout"><span>DropOut</span></a></h2><p>训练的时候每次随机[keep_prob]一部分神经元不参与参数更新，这些神经元的输出被设置为0</p><p>测试的时候关闭</p><h2 id="增大数据量、数据增强" tabindex="-1"><a class="header-anchor" href="#增大数据量、数据增强"><span>增大数据量、数据增强</span></a></h2><h3 id="mixup等方法" tabindex="-1"><a class="header-anchor" href="#mixup等方法"><span>Mixup等方法</span></a></h3><h2 id="early-stop" tabindex="-1"><a class="header-anchor" href="#early-stop"><span>Early Stop</span></a></h2><p>用验证集验证，验证集损失上升时停止训练</p><h2 id="归一化层-batch-normalization" tabindex="-1"><a class="header-anchor" href="#归一化层-batch-normalization"><span>归一化层 Batch Normalization</span></a></h2><p>BN中两个可学习参数相当于引入了噪声、额外的模型规则，让模型难以过拟合训练数据；</p><p>同时BN因为解决了内部协变量偏移问题，可以让模型学习效果变好，从而提高模型泛化能力</p>',35),p=[n];function o(r,s){return t(),a("div",null,p)}const d=e(l,[["render",o],["__file","7.过拟合正则化.html.vue"]]),m=JSON.parse(`{"path":"/deeplearning/ml-basic/7.%E8%BF%87%E6%8B%9F%E5%90%88%E6%AD%A3%E5%88%99%E5%8C%96.html","title":"过拟合[正则化]","lang":"zh-CN","frontmatter":{"title":"过拟合[正则化]","order":7,"copyright":"<a href=\\"https://creativecommons.org/licenses/by-nc/4.0/\\">CC BY-NC 4.0协议</a>","description":"过拟合：模型学习能力太强，学到了样本数据不具备普遍性的特征 泛化性：模型应用到新样本的能力 一般解决方法： 特征选择：丢弃一些不能帮助我们正确预测的特征。可以是手工选择保留哪些特征，或者使用一些模型选择的算法来帮忙（例如PCA） 正则化：保留所有特征，但是减少参数量，降低模型复杂度，从而防止过拟合 得到更多数据：增大数据量、数据增强 正则化 原理：通过...","head":[["meta",{"property":"og:url","content":"https://vuepress-theme-hope-docs-demo.netlify.app/KKBlog/deeplearning/ml-basic/7.%E8%BF%87%E6%8B%9F%E5%90%88%E6%AD%A3%E5%88%99%E5%8C%96.html"}],["meta",{"property":"og:site_name","content":"KK's Blog"}],["meta",{"property":"og:title","content":"过拟合[正则化]"}],["meta",{"property":"og:description","content":"过拟合：模型学习能力太强，学到了样本数据不具备普遍性的特征 泛化性：模型应用到新样本的能力 一般解决方法： 特征选择：丢弃一些不能帮助我们正确预测的特征。可以是手工选择保留哪些特征，或者使用一些模型选择的算法来帮忙（例如PCA） 正则化：保留所有特征，但是减少参数量，降低模型复杂度，从而防止过拟合 得到更多数据：增大数据量、数据增强 正则化 原理：通过..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://pq18uqc90b.feishu.cn/space/api/box/stream/download/asynccode/?code=MGI3NGFhNmUyOGE1ZmI2ZDhmZGJlY2I0NGVjZDk4N2JfbVNtYXU1SzM3dDhQZTZMOVlVZVVJU3pLakdwem8zN1VfVG9rZW46TUk0RmJ5TDdQb2J5bmR4N2hRcmNXWGlQbm9lXzE3NDI4OTk2NzA6MTc0MjkwMzI3MF9WNA"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-03-25T10:49:33.000Z"}],["meta",{"property":"article:author","content":"KK"}],["meta",{"property":"article:modified_time","content":"2025-03-25T10:49:33.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"过拟合[正则化]\\",\\"image\\":[\\"https://pq18uqc90b.feishu.cn/space/api/box/stream/download/asynccode/?code=MGI3NGFhNmUyOGE1ZmI2ZDhmZGJlY2I0NGVjZDk4N2JfbVNtYXU1SzM3dDhQZTZMOVlVZVVJU3pLakdwem8zN1VfVG9rZW46TUk0RmJ5TDdQb2J5bmR4N2hRcmNXWGlQbm9lXzE3NDI4OTk2NzA6MTc0MjkwMzI3MF9WNA\\",\\"https://pq18uqc90b.feishu.cn/space/api/box/stream/download/asynccode/?code=ZGMzZmUxNDgxZjFkMGRjZjBhYWRkMWE1MWMxZDBkOTRfVkZXZjVlallkYXU5N2k0RGZKcEVJTGJGa1hxOEdYN25fVG9rZW46QnJvTGI2SlM3b0dPaDh4UE9lQ2NtVjUwbkZnXzE3NDI4OTk2NzA6MTc0MjkwMzI3MF9WNA\\"],\\"dateModified\\":\\"2025-03-25T10:49:33.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"KK\\",\\"url\\":\\"https://github.com/Nikki-Gu\\"}]}"]]},"headers":[{"level":2,"title":"正则化","slug":"正则化","link":"#正则化","children":[{"level":3,"title":"L1正则化","slug":"l1正则化","link":"#l1正则化","children":[]},{"level":3,"title":"L2正则化","slug":"l2正则化","link":"#l2正则化","children":[]}]},{"level":2,"title":"DropOut","slug":"dropout","link":"#dropout","children":[]},{"level":2,"title":"增大数据量、数据增强","slug":"增大数据量、数据增强","link":"#增大数据量、数据增强","children":[{"level":3,"title":"Mixup等方法","slug":"mixup等方法","link":"#mixup等方法","children":[]}]},{"level":2,"title":"Early Stop","slug":"early-stop","link":"#early-stop","children":[]},{"level":2,"title":"归一化层 Batch Normalization","slug":"归一化层-batch-normalization","link":"#归一化层-batch-normalization","children":[]}],"git":{"createdTime":1742899773000,"updatedTime":1742899773000,"contributors":[{"name":"Nikki-Gu","email":"394632208@qq.com","commits":1}]},"readingTime":{"minutes":2.64,"words":793},"filePathRelative":"deeplearning/ml-basic/7.过拟合正则化.md","localizedDate":"2025年3月25日","autoDesc":true}`);export{d as comp,m as data};
