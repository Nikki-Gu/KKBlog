---
title: 假设检验
order: 1

copyright: <a href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0协议</a>

---



# 统计学知识储备

## 假设检验

A/B实验的核心统计学理论是（双样本）**[假设检验](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing)**。

假设检验：做出假设，然后运用数据来检验假设是否成立。

> 原假设/零假设**（**null hypothesis）：是实验者想要收集证据予以反对的假设。A/B实验中的原假设就是指“新策略没有效果”。
>
> 备择假设（alternative  hypothesis）：是实验者想要收集证据予以支持的假设，与原假设互斥。A/B实验中的备择假设就是指“新策略有效果”。

我们希望证明**备择假设**正确（真），使用**反证法**就要通过一系列方法，利用现有的数据证明**原假设是错误的（伪）**。这一系列方法在统计学上被称作**原假设显著性检验null hypothesis significance testing (NHST)**。

## 两类错误

会有两类错误的原因：抽样会产生误差

> 为了尽量避免错误策略对用户产生影响，我们在进行实验时只会从总体流量中抽取一小部分数据。因此，A/B实验中包含**抽样**这一步骤。尽管我们尽力保持样本流量和总体流量分布一致，但抽样会产生一定的**误差**，这是无法完全避免的。因此，通过抽样收集数据后，对于“原假设”和“备择假设”的检验结果不可能百分之百准确。

万幸的是，通过统计学理论，我们可以知道在检验的过程中，我们**可能会犯什么错**，以及**有多大几率犯错**。统计学告诉我们，在假设检验的过程中，我们可能犯两种错误，它们分别被称为**第一类错误**（弃真）和**第二类错误**（取伪）。

### 第一类错误

第一类错误，指原假设正确（真），但是我们假设检验的结论却显示原假设错误，认为备择假设为真

- 实验结论显示新策略有效，但实际无效
- 实验结论显示新策略有效，因此我们拒绝了正确的原假设，所以第一类错误是“弃真”

### 第二类错误

第二类错误，指原假设错误，但是我们假设检验的结论却显示原假设正确

- 实验结论显示新策略无效，但实际有效
- 实验结论显示新策略无效，因此我们接受了错误的原假设，所以第二类错误是“取伪”

# 显著性水平（α）和P值

显著性水平定义：可容忍在实验中犯第一类错误的概率

作用：用于量化抽样误差带来的不确定性

### 理论依据

我们可以量化抽样误差的根基在于**[中心极限定理](https://zh.wikipedia.org/wiki/中心极限定理)**的存在。

中心极限定理：

- 真值：从总体中抽取样本并计算其指标的均值时，每次计算都会受到抽样误差的影响。假设我们进行无数次实验，理论上，这无数个样本均值中总会有一个是“真实的”，即不受抽样误差影响的值，在统计学中被称为**“真值”**
- 中心极限定理证明：如果我们从总体流量里不断抽取样本，做无数次小流量实验，这无数次抽样所观测到的均值，近似呈现**正态分布**，这个分布以真值为中心，**均值越接近真值，出现的概率就越大；反之均值越偏离真值，出现的概率就越小。**

### 实际应用

P值：P值是一个概率值，用于量化在零假设（H₀）为真的前提下，观察到端值的概率。

说人话就是：

- 当前结论受到抽样误差影响的概率大小。P值用于衡量在零假设为真的情况下，观测结果与零假设为真不符是由于抽样抽到极端数据的概率

  这个概率越小，说明当前观测到的结果是由抽样误差导致的概率越小

统计学根据显著性检验方法所得到的P 值，一般以「P < 0.05 为有统计学差异」， P<0.01 为有显著统计学差异，P<0.001为有极其显著的统计学差异。

当实验结果显示p-value<5%，则你的策略大概率[大于95%]是有效的，这里95%就被称为置信水平。（在不考虑第二类错误的情况下）



# 检验方法

## P值的计算步骤

1. **假设检验类型**：首先，确定你要进行的假设检验的类型（例如 t检验，卡方检验，Z检验等）。
2. **计算检验统计量**：根据你的数据和假设检验类型计算检验统计量（如 t值、Z值、卡方值等）。
3. **累积分布函数（CDF）**：使用检验统计量的累积分布函数（CDF）来计算 P值。CDF 给出了小于或等于某给定值的事件的累计概率。
4. **单尾或双尾检验**：P值计算方式不同
   - **双尾检验（Two-Tailed Test）**：检查检验统计量在双侧是否有显著差异。适用于不知道差异方向或对任何方向上差异感兴趣的情况。例如，两种治疗方法的疗效是否相同。
   - **单尾检验（One-Tailed Test）**：只检查检验统计量在一侧是否有显著差异，适用于有明确方向假设的情况。例如，新的治疗方法效果是否优于旧方法。

## T检验

t检验（t-test，也称t值检验）是统计学中用于比较两个样本均值差异的检验方法。t检验通过比较两个样本的均值，分析它们之间是否存在统计显著性差异。

### 三种t检验

常用的t检验有三种类型：单样本t检验、独立样本t检验和配对样本t检验。

1. 单样本 t 检验（One-Sample t-Test）

   用于测试样本均值与已知的总体均值（或目标值）之间是否存在显著差异。例如，你想知道某班级学生的平均成绩是否不同于全校的平均成绩。

2. 独立样本 t 检验（Independent Samples t-Test）

   用于比较两个独立样本的均值是否存在显著差异。例如，你想比较实验组和对照组的平均成绩。

   **计算 t 值（t-statistic）**： t 值表示样本均值与总体均值的标准化差异。

   $t = \frac{\bar{X}_1 - \bar{X}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}$

   计算自由度：

   $[ \text{df} = \frac{\left(\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}\right)^2}{\frac{\left(\frac{s_1^2}{n_1}\right)^2}{n_1 - 1} + \frac{\left(\frac{s_2^2}{n_2}\right)^2}{n_2 - 1}} ]$

   $[ t_{\text{score}} = \left| t \right| ]$

3. 配对样本 t 检验（Paired-Samples t-Test）

   用于比较两个相关样本的均值是否存在显著差异。例如，测试前后的成绩是否有显著变化。

### t 检验的基本原理

在 t 检验中，假设检验为：

- **零假设（H₀）**：假设两个组的均值没有显著差异。
- **备择假设（H₁）**：假设两个组的均值有显著差异。

t 检验通过计算 t 统计量，结合自由度找到对应的 P 值来做出决策。如果 P 值小于预定的显著性水平（通常为 0.05 或 0.01），则拒绝零假设，认为两个组之间存在显著差异。

### 代码实现

```
def show_p_value():
    # 计算每个特征的 t 值和 p 值
    result = {}

    for item in numerical_columns:
        mean_c = control_stats[f"{item}_mean_c"]
        mean_t = treatment_stats[f"{item}_mean_t"]
        var_c = control_stats_2[f"{item}_var_c"]
        var_t = treatment_stats_2[f"{item}_var_t"]
        
        # 计算 t 值
        t_score = (mean_t - mean_c) / np.sqrt((var_t / treatment_n) + (var_c / control_n))
        # 计算自由度
        df = ((var_t / treatment_n) + (var_c / control_n))**2 / ((var_t**2 / ((treatment_n**2) * (treatment_n - 1))) + (var_c**2 / ((control_n**2) * (control_n - 1))) + 1e-10)
        
        # 计算 p 值（双尾检验）
        p_value = 2 * (1 - t.cdf(np.abs(t_score), df)) # t分布的累计分布函数cdf
        result[item] = p_value

    # 结果解释
    alpha = 0.05  # 显著性水平
    num = 0
    print("在实验组和对照组之间存在显著差异的特征:")
    for feature, p_value in result.items():
        if p_value < alpha:
            num = num + 1
            print(f"{feature} (P-Value: {p_value:.5f})")
    print("有显著差异的特征数量:", num)
```

计算P值的步骤解释：

- 计算t值并取绝对值：np.abs(t_score)

- **计算单侧累积概率**： 使用学生 t 分布的累积分布函数（CDF）计算单侧的累积概率，表示 t 统计量小于或等于观测值的概率。	t.cdf(np.abs(t_score), df)

  给定一个 t 统计量（观测值），在零假设为真的情况下，t 分布中的随机变量小于等于这个 t 统计量的概率。这就是单侧累积概率

- **计算单侧概率**： 单侧概率表示 t 值绝对值大于观测值的概率。[ \text{single_tail_prob} = 1 - \text{single_tail_p} ]

- **计算双尾概率**： 双尾概率表示 t 值在两个尾端的总概率（即双侧都可能出现极端值的概率）。

  [ p_{\text{value}} = 2 \times \text{single_tail_prob} ] 由于 t 分布是对称的，我们将单侧概率乘以 2 得到双尾概率

  因此p_value = 2 * (1 - t.cdf(np.abs(t_score), df))

## Z检验

用于比较样本均值和总体均值或两个样本均值之间的差异。**它基于标准正态分布（Z分布）,适用于大样本的情况或已知总体方差的情况**

和t检验的比较：Z检验与t检验非常相似，但有一些关键区别：

- **样本大小**：Z检验通常用于大样本（一般认为n > 30），而t检验适用于小样本。
- **已知方差**：Z检验适用于已知总体方差，而t检验适用于方差未知的情况。

### 两种Z检验

1. 单样本Z检验

   (样本均值-总体均值) / {总体标准差/sqrt(样本大小)}

   $Z = \frac{\bar{X} - \mu}{\frac{\sigma}{\sqrt{n}}}$

2. 双样本Z检验公式

   $Z = \frac{\bar{X}_1 - \bar{X}_2}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}}$

   其中：

   - (\bar{X}_1) 和 (\bar{X}_2)：两个样本的均值
   - (\sigma_1) 和 (\sigma_2)：两个总体的已知标准差
   - (n_1) 和 (n_2)：两个样本的大小

## 卡方检验





# 思考

1. ## 原假设和被择假设能交换吗？

**不能。**

我们期望的不断推翻我们的原假设，使产品不停的向前迭代，因此我们非常自信的用一个5%的容错率来证明，我们的迭代方向没有错。如果换过来，所有的计算都可以同样进行，但我们只能非常自信的告诉别人，产品没有效果，而不能很自信的告诉别人产品有效果。**这里也从本质上说明AB实验实质上是一个证伪实验，并不是一个求真实验，我们应该把我们希望被证明的事情，放在被择假设中。**

1. ## 实验数据显著，全量上线后就万事大吉了吗？

**不是。**

尽管我们将犯第一类错误的概率设定为5%，但是，正如“常在河边走，哪能不湿鞋”，即使概率很低，随着迭代次数的增多，必然会出现。因此，最佳做法是定期关注数据指标的整体变化。

# 参考资料&推荐阅读

[数据漫游指南《A/B测试》系列文章](https://site.bytedance.net/docs/860/1076/relatedcourses/?cutfrom=arcosite)

[关于AB实验——“显著”指代什么？](https://bytedance.larkoffice.com/wiki/Jkszwq2sVi9NZqkSWDfcppasnMd)